---
title: "0624_R 통계 2"
output:
  html_document:
    toc: true
    toc_float: true
    keep_md: true
date: '2022-06-24'
---


## 복습
- 통계 검정
  + 평균 차이 검정 : 수치 데이터 + 범주 데이터(두 그룹)
    - 중급 이상 : 세 그룹 이상 평균 차이 검정
  + 비율 차이 검정 : 범주 데이터 
  + 상관 관계 : 수치 데이터
  + 회귀
  
- 통계 검정 사전 준비
  + 분석을 위한 데이터가 적정한지 검정
  + 등분산 검정, 수치 데이터가 정규 분포를 이루는가 (정규성 검정)
  
- 귀무 가설, 대립가설 적절하게 설정
  + 서울이 부산보다 잘 살 것이다 -> 가설이 될 수 없음
  + 서울의 평균 임금과 부산의 평균 임금이 차이가 있을 것이다 -> 가설 설정 가능
  + 선행연구 (논문 찾아서 응용)
  
- 테스트
  + t.test, chisq.test, cor.test
  + p.value > 0.05 -> 귀무가설 지지
  + p.value < 0.05 -> 대립가설 지지
  
## 회귀의 중요성
- 기초통계 : 특정한 결과에 영향을 주는 주 요인을 찾는 것이 회귀
- 회귀분석과 종류
  + 1세대 회귀 방법론 :다항 회귀분석, 다중 회귀분석, 포아송 회귀분석, etc
  + 2세대 회귀 방법론 : 구조방정식

- 귀무가설 & 대립가설 존재
  + 귀무가설 : x(=독립변수)가 y(=종속변수)에 영향을 주지 않는다
  + 대립가설 : x가 y에 영향을 준다
  
- 전진 소거법, 후진 소거법  
  
- lm(종속변수 ~ 독립변수, data)
  + p.value

```r
RA <-lm(data=mtcars, mpg ~ disp)
summary(RA)
```

```
## 
## Call:
## lm(formula = mpg ~ disp, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.8922 -2.2022 -0.9631  1.6272  7.2305 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 29.599855   1.229720  24.070  < 2e-16 ***
## disp        -0.041215   0.004712  -8.747 9.38e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.251 on 30 degrees of freedom
## Multiple R-squared:  0.7183,	Adjusted R-squared:  0.709 
## F-statistic: 76.51 on 1 and 30 DF,  p-value: 9.38e-10
```
 - p.value 값을 하나씩 빼가면서 진행해야 함. 
 - 컬럼갯수가 많더라도 진행해야 함.

- Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 29.599855   1.229720  24.070  < 2e-16 ***
disp        -0.041215   0.004712  -8.747 9.38e-10 ***

var1                                     0.10
var2                                     9.38e-10 ***                            
var3                                     0.78

y = ax + bx + c

Residual standard error: 3.251 on 30 degrees of freedom
Multiple R-squared:  0.7183,	Adjusted R-squared:  0.709 
F-statistic: 76.51 on 1 and 30 DF,  p-value: 9.38e-10
 
 - R-squared : 결정계수 = 설명력
   + 1로 수렴할수록 설명력이 좋다 -> 
     1을 수렴하지 못할경우 나머지를 채울 수 있는 요인을 찾아내야 함.

- ANOVA (분산분석)을 통해서 식 1, 식2 ...를 활용해 식을 도출해야 함.
  + 식 1 : y = disp + var1 + var2 + var3 
  + 식 2 : y = disp + var1 + var2

- Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 29.599855   1.229720  24.070  < 2e-16 ***
disp        -0.041215   0.004712  -8.747 9.38e-10 ***

y(mpg) = 29.59985- 0,04125 x disp
  
  
- 머신러닝, 인공지능
  + 주 목적 -> 예측
  + y = ax +b
  + 인공지능이 시작은 회귀에서 부터 시작됨


 - 회귀분석에서 고려해야 할 것들
 1. 전체 식의 p.value 값이 0.05보다 작은지
 2. ANOVA를 통해서 식1, 식2 등을 활용해 도출해야함.
 3. 식을 작성할 줄 알아야 함. 
 4. R-squared(결정계수)가 1에 수렴하는지 확인 후 수렴되지 않는 경우 요인에 대해 분석해야 함.

